---
marp: true
theme: my-theme
paginate: true
---
# 졸업프로젝트 중간점검
### 3월 과제: Keras 연습
응용미술교육과 
2018030328 신영은

---
# 목차
1. 신경망의 구조
2. **MLP**
    1. 이진 분류 문제: IMDB 데이터셋
    2. 다중 분류 문제: 로이터 데이터셋
    3. 회귀 문제: 보스턴 주택 데이터셋
3. **모델 튜닝**
    1. 네트워크 크기 축소
    2. 드롭아웃 추가
    3. 가중치 규제 추가
4. **CNN**
    1. 작은 데이터셋 이진 분류 문제: Kaggle Cats vs Dog
    2. 사전 훈련된 Convnet 사용하기: VGG16
    3. Convnet의 학습 시각화하기
---
# 1. 신경망의 구조
* 신경망의 구성 요소간의 관계
![width:750px](https://blog.kakaocdn.net/dn/btlekM/btqzhhoqubL/klqNFRPkBWSakQMZrNd4Bk/img.png)

---
# 1. 신경망의 구조
## 1.1. 층
* 하나 이상의 텐서를 입력받아 하나 이상의 텐서를 출력하는 데이터 처리 모듈
* 대부분의 층은 **가중치**라는 상태를 가짐

### 1.1.1. 가중치
* **확률적 경사 하강법**에 의해 학습
* 훈련 데이터를 신경망에 노출시켜 학습된 정보를 가짐
* 피드백 신호에 기초해 점진적으로 조정됨
---
# 1. 신경망의 구조
### 1.1.2. 활성화 함수
* 이전 층의 결과값을 변환하여 다른 층으로 신호를 전달하는 역할
![width:700px](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbeswMt%2FbtqYpV2m5DU%2Fvqv8wX4oRhlM99eqhQIRx0%2Fimg.png)
---
# 1. 신경망의 구조
### 1.1.2. 층의 종류
#### 1.1.2.1 완전 연결 층 (fully connected layer)
* 2D 텐서가 저장된 간단한 벡터 데이터 처리
* keras에서는 ```Dense``` class
#### 1.1.2.2. 순환 층 (recurrent layer)
* 3D 텐서로 저장된 시퀀스 데이터 처리
* ```simple RNN```, ```LSTM``` 등
#### 1.1.2.3. 2D 합성곱 층 (convolution layer)
* 4D 텐서로 저장된 이미지 데이터 처리
* ```conv2D``` class
---
# 1. 신경망의 구조
## 1.2. 모델
* 층으로 만든 DAG(Directed Acyclic Graph)
* 네트워크 구조는 **가설 공간**을 정의함
    * 가설 공간(space of hypotheses)
        * 어떤 문제를 해결하는데 필요한 가능성 있는 가설 후보군의 집합
    * 네트워크 구조를 선택함으로써 가설 공간을 입력 데이터에서 출력 데이터로 매핑하는 일련의 특정 텐서 연산으로 제한
---
# 1. 신경망의 구조
## 1.3. 손실 함수
* 예측값과 실제값의 차이를 계산 -> **훈련하는 동안 최소화되야함**
### 1.3.1. 문제 유형에 맞는 손실 함수
|문제 유형|마지막 층의 활성화 함수|손실 함수|
|------|---|---|
|이진 분류|sigmoid|binary_crossentropy|
|단일 레이블 다중 분류|softmax|categorical_crossentropy|
|다중 레이블 다중 분류|sigmoid|binary_crossentropy|
|임의 값에 대한 회귀|-|mse|
|0과 1 사이 값에 대한 회귀|sigmoid|mse or binary_crossentropy|
## 1.4. 옵티마이저
* 손실 함수를 기반으로 네트워크가 어떻게 업데이트될지 결정
* 특정 종류의 확률적 경사 하강법을 구현
---
# 2. MLP 예제
## 2.1. 이진 분류 문제
> IMDB dataset 영화 리뷰 분류
### 2.1.1. 데이터 준비하기
#### 2.1.1.1 IMDB 데이터셋 로드 후 훈련, 테스트 데이터로 나누기
* 훈련과 테스트를 같은 데이터로 하면 안됨!
    * 모델은 처음 보는 데이터에 대한 성능이 중요!
    * 모델에는 이미 훈련 데이터에 맞는 규칙이 반영되었기 때문에 성능 평가 단계에서는 학습에 사용되지 않은 데이터 사용

    ```python
    from keras.datasets import imdb
    # 가장 자주 사용되는 단어 10,000개만 사용
    (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)
    ```
---
## 2.1. 이진 분류 문제
### 2.1.1. 신경망에 주입할 데이터 준비하기
* 숫자 리스트를 원-핫 인코딩하여 0과 1의 벡터로 변환 
* **원-핫 인코딩**:
    1. 단어 집합의 크기를 벡터의 차원 만들기 
    2. 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스는 모두 0으로 만들기

    ```python
    def vectorize_sequences(sequences, dimension=10000):
        results = np.zeros((len(sequences), dimension))
        for i, sequence in enumerate(sequences):
            results[i, sequence] = 1.
        return results
    ```
---
## 2.1. 이진 분류 문제
### 2.1.2. 신경망 모델 만들기
#### 2.1.2.1 완전 연결 신경망
* ```relu``` 활성화 함수를 사용한 ```Dense```층 쌓기
    1. 16개의 은닉 유닛을 가진 두 개의 은닉층
    2. 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 마지막 층
        * ```sigmoid```사용: 임의의 값을 [0, 1] 사이로 압축 -> 출력 값을 **확률**처럼 해석
    ```python
    from keras import models
    from keras import layers

    model = models.Sequential()
    model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))
    model.add(layers.Dense(16, activation='relu'))
    model.add(layers.Dense(1, activation='sigmoid'))
    ```
---
## 2.1. 이진 분류 문제
#### 2.1.2.2. 옵티마이저, 손실함수 설정
* 옵티마이저: rmsprop
* 손실함수: 
    * 이진 분류 -> binary_crossentropy
    * 확률을 출력하는 모델이므로 확률 분포 간의 차이를 측정하는 크로스엔트로피 쓰기 (원본 분포와 예측 분포 사이를 측정)
    ```python
    model.compile(optimizer='rmsprop',
                loss='binary_crossentropy',
                metrics=['accuracy']) # 정확도를 사용해 모니터링
    ```
---
## 2.1. 이진 분류 문제
### 2.1.3. 훈련 & 검증하기
#### 2.1.3.1. 검증 세트 만들기
* 훈련 데이터에서 일부 데이터 떼어내 검증 세트 만들기
* 검증용 데이터는 훈련에서 사용되면 안됨! (처음 본 데이터에 대한 모델의 정확도 측정)
#### 2.1.3.2. 모델 훈련하기
* ```model.fit()```: 
    * ```History``` 객체 반환
    * 훈련하면서 발생한 모든 정보를 담고있는 딕셔너리  ```history```속성을 가짐
    ```python
    history = model.fit(partial_x_train,
                        partial_y_train,
                        epochs=20,
                        batch_size=512,
                        validation_data=(x_val, y_val))
    ```
---
## 2.1. 이진 분류 문제
#### 2.1.3.3. 훈련과 검증 그래프
* matplot으로 훈련과 검증 손실 & 정확도 그래프 그리기
![width:850px](./image/binary_graph.png)
* 4번째 epoch부터 **과대적합** 발생!
    * 훈련 데이터에 과도하게 최적화되어 새로운 데이터에 일반화 X
    * 과대적합 발생 전까지만 훈련하고 테스트데이터로 평가하기
---
## 2.1. 이진 분류 문제
### 2.1.4. 테스트 데이터에서 평가
* 과대적합 발생 전까지만 훈련한 후 test 데이터로 평가하기
* ```evaluate()```: 모델의 최종적인 정답률과 loss값 알 수 있음
    ```python 
    results = model.evaluate(x_test, y_test)
    ```
### 2.1.5. 훈련된 모델로 새로운 데이터에 대해 예측하기
* ```predict()```: 데이터가 양성 샘플(label=1)일 확률 예측
    ```python
    model.predict(x_test)
    ```
### 2.1.6. 정리
1. 원본 데이터를 신경망에 주입 전에 **전처리** 하기
1. 출력 class가 2개인 **이진분류** 문제는 **1개의 unit**과 **Sigmoid** 활성화 함수를 가진 Dense 층으로 끝내기
2. 이진 분류의 스칼라 sigmoid 출력에는 **binary_crossentropy** 손실함수 쓰기
---
## 2.2. 다중 분류 문제
> 로이터 dataset 뉴스 토픽(46가지) 분류
### 2.2.1. 신경망에 주입할 데이터 준비하기
* 가장 자주 사용되는 단어 10,000개를 제한으로 데이터 load
* 이진 분류와 동일한 방식인 원-핫 인코딩으로 벡터화
    * 케라스 내장 함수 ```to_categorical```사용
        ```python
        from keras.utils.np_utils import to_categorical

        one_hot_train_labels = to_categorical(train_labels)
        one_hot_test_labels = to_categorical(test_labels)
        ```
---
## 2.2. 다중 분류 문제
### 2.2.2. 모델 구성
* 출력 class: 46개 (46가지 토픽으로 분류)
    * 마지막 층 
        * 크기: 46
        * 활성화 함수: ```softmax``` (샘플이 각 46개 class에 속할 확률분포 출력)
    * 은닉 유닛 갯수를 64개로 증가
        * 이진 분류 예제와 달리 유닛이 너무 작으면 정보의 **병목** 현상으로 유용한 정보를 잃을 수 있음
* 손실함수: ```categorical_crossentropy``` -> 출력한 확률 분포와 진짜 레이블 분포 간의 거리
    ```python
    from keras import models
    from keras import layers

    model = models.Sequential()
    model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dense(46, activation='softmax'))

    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
    ```
---
## 2.2. 다중 분류 문제
### 2.2.3. 훈련 검증
* train 데이터셋 일부(1000개)를 떼어내 검증 셋으로 사용
![width:730px](./image/mul_graph.png)
* 8번 에포크 이후 과대적합 발생 -> 에포크 8번으로 감소한 후 테스트

---
## 2.2. 다중 분류 문제
### 2.2.4. 테스트 결과
* 약 78% 정확도 달성
### 2.2.5. 정리
* N개의 클래스로 데이터 분류 -> 마지막 Dense 층 크기: N
* 단일 레이블 다중 분류 문제는 활성화 함수```softmax```사용.(N개의 클래스에 대한 확률 분포를 출력)
* loss함수 ```categorical_crossentropy``` 사용. (모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화)
* 많은 수의 범주로 분류할 때 중간층의 크기 충분하게 -> **정보의 병목** 생기지 않도록!
---
## 2.3. 회귀 문제
> boston 주택 가격 예측
### 2.3.1. 데이터 준비
* 개수가 적은 데이터 셋(총 506개)
    * 훈련 샘플 404개, 테스트 샘플 102개
* 입력 데이터의 각 특성(총 13개)의 스케일이 서로 다름
    * 네트워크에 주입 전 **특성별로 정규화** -> 특성의 중앙 0 근처에 맞춤 +  표준 편차 1로
        ```python
        mean = train_data.mean(axis=0)
        train_data -= mean # 평균을 빼고
        std = train_data.std(axis=0)
        train_data /= std # 표준 편차로 나누기

        test_data -= mean
        test_data /= std
        ```
    * 정규화 시 **훈련 데이터에서 계산한 값** 사용!
        * 훈련 시 절대 테스트 데이터에서 계산한 값을 사용하면 안됨,,
---
## 2.3. 회귀 문제
### 2.3.2. 모델 구성
* 샘플의 수가 적으므로 과대적합 일어나기 쉽다
    * **작은 모델** 사용하기: 64개 unit 가진 2개의 층
* 마지막 층: **선형 층** (활성화 함수 없음)
    * 어떤 범위의 값이라도 예측하도록 자유롭게 학습 가능!
* 손실함수 : ```mse```(평균 제곱 오차) -> 예측과 타깃 사이 거리의 제곱
* 모니터링 : ```mae```(평균 절대 오차)
    ```python
    model = models.Sequential()
    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dense(1))
    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])
    ```
---
## 2.3. 회귀 문제
### 2.3.3. k-fold 교차검증으로 훈련 검증
* 작은 데이터셋 -> 검증 세트와 훈련 세트로 어떤 데이터가 선택됐는지에 따라 검증 점수가 크게 달라지게 된다!
#### 2.3.3.1. K-fold 교차 검증
* 데이터를 K개의 폴드로 나누고, K개의 모델을 각각 만들어 K - 1개의 분할에서 훈련하고 나머지 분할에서 평가하기
* 검증 점수: K 개의 검증 점수의 평균
![width:600px](https://user-images.githubusercontent.com/26396102/48558221-2564dc80-e92c-11e8-9110-73adacf514e1.PNG)
---
## 2.3. 회귀 문제
#### 2.3.3.2. 검증 결과
* 모든 폴드에 대한 에포크의 MAE 평균 그래프
![width:450px](./image/reg_val.png)
* 약 80번째 에포크 이후 과대적합 
    * 에포크 80번으로 줄인 후 전체 훈련 데이터(훈련+검증)로 모델 훈련 
---
## 2.3. 회귀 문제
### 2.3.4. 테스트 결과
* 테스트 데이터로 성능 확인 : ```evaluate()```사용
* 약 2,774$ 차이
### 2.3.5. 정리
1. 스칼라 회귀 문제는 ```MSE``` 손실함수 사용.
2. 평가 지표: ```MAE```평균 절대 오차
3. 입력 데이터 특성이 서로 다른 범위를 가지면 전처리 단계에서 각 특성별 **스케일 조정**
4. 데이터가 적을땐 **K-fold 교차검증** 사용
5. 훈련 데이터가 적을땐 과대적합 방지를 위해 **작은 모델** 사용
---
# 3. 모델 튜닝
### 3.0.1. 최적화 vs 일반화
* 최적화: 가능한 훈련 데이터에서 최고의 성능을 얻기위해 모델 조정(머신 러닝의 학습) 
* 일반화: 훈련된 모델이 처음 보는 데이터에서 얼마나 잘 수행되는가?
### 3.0.2. 과소적합 vs 과대적합
#### 3.0.2.1. 과소적합
* 훈련 데이터의 손실이 낮을수록 테스트 데이터의 손실이 낮은 상황
* 네트워크가 훈련 데이터에 있는 관련 특성을 모두 학습하지 못함 -> 모델 성능이 계속 발전될 여지 있다!
#### 3.0.2.2. 과대적합
* 훈련 데이터에 여러 번 반복 학습하면 어느 시점부터 일반화 성능이 더이상 높아지지 않음
* 검증 세트 성능이 멈추고 감소
* 훈련 데이터에 특화된 패턴을 학습하기 시작 -> 패턴은 새로운 데이터와 관련성 적어..
---
# 3. 모델 튜닝
### 3.0.3. 일반화 성능이 뛰어난 모델 만들기
1. 많은 훈련 데이터 모으기
2. 모델이 수용할 수 있는 정보의 양을 조절하거나 저장할 수 있는 정보에 제약을 가하기
## 3.1. 네트워크 크기 축소
> 적은 수의 패턴만을 기억할 수 있다면 최적화 과정에서 가장 중요한 패턴에 집중하게 된다.
### 3.1.1. 파라미터 줄이기
* 파라미터 갯수: 층의 수 & 각 층의 unit 수에 의해 결정
    * 파라미터가 많은 모델이 기억 용량이 더 많다.. -> 너무 많으면 일반화 안됨
* **기억 용량에 제한** -> 타깃에 대한 예측 성능을 가진 **압축된 표현**을 학습!
* 단, 과소적합되지 않도록 절충점 찾기
---
## 3.1. 네트워크 크기 축소
### 3.1.2. 모델 용량 제한 결과
![width:700px](./image/capacity.png)
* 큰 네트워크:
    * 훈련 손실: 빠르게 0으로
    * 검증 손실: 4번째 에포크부터 과대적합
* 작은 네트워크:
    * 훈련 손실: 천천히 줄어듦
    * 검증 손실: 8번째 에포크부터 과대적합
---
## 3.2. 드롭아웃 추가
> 층의 출력 값에 노이즈를 추가하여 중요하지 않은 우연한 패턴을 깨뜨리기
### 3.2.1. 드롭아웃
* 훈련하는 동안 무작위로 층의 일부 출력 특성을 제외(0으로)
* 드롭아웃 비율: 0이 될 특성의 비율(보통 0.2-0.5)
* keras에서는 층의 출력 바로 뒤에 ```Dropout``` 추가하여 적용 (예시: ```model.add(layers.Dropout(0.5))```)
### 3.2.2. 드롭아웃 결과
![width:350px](./image/dropout.png)

---
## 3.3. 가중치 규제 추가
> 가중치가 작은 값을 가지도록 강제하기

### 3.3.1. 가중치 규제
#### 3.3.1.1. L1 규제
* 가중치의 **절대값**에 비례하는 비용 추가
* 일부 가중치 값을 완전히 0으로 만들 수 있음
#### 3.3.1.2. L2 규제
* 가중치의 **제곱**에 비례하는 비용 추가
* 가중치 감쇠 라고도 부름: **가중치** W가 클수록 더 큰 **페널티**를 부과해 inpux 'x'에 대해 지나치게 fit 하지 않도록
* 가중치 값을 작게 만들지만 완전히 0이 되지 않음
---
## 3.3. 가중치 규제 추가
### 3.3.2. 가중치 규제 결과
* l1(0.0001), l2(0.001)
* 같은 파라미터 수를 가지고 있어도 과대적합에 잘 견디고 있음.
![width:900px](./image/l1_l2.png)

---
# 4. CNN
## 4.1. 작은 데이터셋 이진 분류 문제
> Kaggle Cats vs Dog
### 4.1.1. 합성곱 신경망 (Convnet)
* **지역 패턴**을 학습: 이미지의 경우 2D 윈도우로 입력에서 패턴을 찾는다
* **평행 이동 불변성**: 적은 수의 훈련 샘플을 사용해 일반화 능력을 가진 표현을 학습
* **패턴의 공간적 계층 구조를 학습**: 작은 지역 패턴 -> 더 큰 패턴 학습
#### 4.1.1.1. 합성곱 계층
* **특성 맵**
    * 합성곱 계층의 입출력 데이터
* **필터**
    * 입력 데이터의 어떤 특성을 인코딩
    * 입력 데이터를 지정 간격(Stride)으로 순회하면서 합성곱 계산
---
## 4.1. 작은 데이터셋 이진 분류 문제
#### 4.1.1.2. 패딩
* 출력 크기를 조정하기 위해 사용
    * 합성곱 연산을 거칠 때마다 출력 특성맵의 크기가 작아져 결국 1이 되어버림 -> 더 이상 합성곱 연산 불가
    * 입력과 **크기가 동일한 특성 맵** 출력 가능
* 입력 특성 맵의 가장자리에 0으로 채워진 행과 열을 추가
#### 4.1.1.3. 스트라이드
* 2번의 연속적인 윈도우 사이의 거리
* Stride > 1로 설정 시 특성 맵 다운샘플링
#### 4.1.1.4. Maxpooling
* 특성 맵을 **다운샘플링**
    * 처리할 특성 맵의 가중치 개수 줄이기
    * 필터의 공간적인 계층 구조 형성
* 대상 영역에서 **최댓값**을 취하기(최대로 활성화 된 특성 선택 -> 특성 희석 방지)
---
## 4.1. 작은 데이터셋 이진 분류 문제
### 4.1.2. 네트워크 구성하기
* ```Conv2D```(```relu``` 활성화 함수 사용)와 ```MaxPooling2D``` 층을 번갈아 쌓은 **컨브넷** 만들기
* 마지막 층: 이진분류이므로,, ```sigmoid``` + 유닛 1개
![width:400px](./image/model_summary.png)

---
## 4.1. 작은 데이터셋 이진 분류 문제
### 4.1.3. 데이터 전처리
* 네트워크에 JPEG 이미지 주입하기 위해 데이터 전처리
    1. 사진 파일 JPEG 콘텐츠를 RGB 픽셀 값으로 디코딩
    2. 부동 소수 타입의 텐서로 변환
    3. 픽셀 값(0에서 255 사이)의 스케일을 [0, 1] 사이로 조정 (신경망은 작은 입력 값을 선호하기 때문)
* ```keras.preprocessing.image```의 ```ImageDataGenerator```클래스로 이미지 파일을 배치 텐서로 바꾸는 제너레이터 만들기

### 4.1.4. 배치 제네레이터를 사용해 모델 훈련
* 하나의 에포크 정의하기 위해 **제너레이터로부터 얼마나 많은 샘플 뽑을지** 지정
    * steps_per_epoch: 전체 훈련 데이터 수 / train_generator 배치 수
    * validation_step: 전체 검증 데이터 수 / validation_generator 배치 수
---
## 4.1. 작은 데이터셋 이진 분류 문제
### 4.1.5. 데이터 증식
* 학습할 샘플이 너무 적으면 새로운 데이터에 일반화할 수 있는 모델을 훈련시킬 수 없음 (과대적합 발생) 
**-> 기존의 훈련 샘플로부터 더 많은 훈련 데이터를 생성하자!**
* keras에서는 ```ImageDataGenerator```를 이용해 이미지에 여러 종류의 랜덤 변환을 적용할 수 있음
![width:750px](./image/data_augmentation.png)
* 단, 검증 데이터와 테스트 세트는 증식 X
### 4.1.6. 드롭아웃 적용하기
* 증식된 이미지는 적은 수의 원본 이미지에서 만들어졌기 때문에 여전히 입력 데이터들 사이에 상호 연관성이 큼
* 과대적합을 억제하기 위해 완결연결층 전에 **드롭아웃 층** 추가
---
## 4.1. 작은 데이터셋 이진 분류 문제
### 4.1.7. 훈련과 검증 결과
* 데이터 증식 & 드롭아웃 적용 전
![width:490px](./image/cnn_small_1.png)
* 데이터 증식 & 드롭아웃 적용 후
![width:490px](./image/cnn_small_2.png)
    * 훈련과 검증 그래프 가까워짐
---
## 4.2. 사전 훈련된 Convnet 사용하기
> VGG16 컨브넷 구조 사용
### 4.2.1. 사전 훈련된 네트워크
* 일반적으로 대규모 이미지 분류 문제를 위해 **대량의 데이터셋에서 미리 훈련되어 저장된 네트워크**
### 4.2.2. 특성 추출
#### 4.2.2.1. 합성곱 층 재사용하기
* 합성곱 층에 의해 학습된 표현은 **일반적**이어서 재사용 가능하다!
    * 완전 연결 분류층은 모델이 훈련된 클래스 집합에 특화되어있으므로 **합성곱 층만 재사용**
* 층의 깊이에 따라 층에서 추출한 표현의 일반성(재사용성)의 수준이 다르다!
    * **하위 층**: 지역적이고 매우 **일반적**인 특성맵(에지, 색깔, 질감 등) 추출
    * 상위 층: 좀 더 **추상적**인 개념('강아지 눈', '고양이 귀'등) 추출
    * 새로운 데이터셋이 원본 모델이 훈련한 데이터셋과 많이 다르면 모델의 하위 층 일부만 특성 추출에 사용    
---
## 4.2. 사전 훈련된 Convnet 사용하기
#### 4.2.2.2. Case1: 데이터 증식을 사용하지 않는 빠른 특성 추출
> 새로운 데이터셋에서 합성곱 기반 층 실행 후 출력 -> **독립된 완전 연결 분류기**에 입력
* 사전 훈련된 합성곱 기반 층을 사용한 특성 추출:
    ```ImageDataGenerator```를 사용해 이미지와 레이블을 넘파이 배열로 추출 (디스크에 저장)
* 빠르고 cost 적음
* **데이터 증식 사용 불가**
![width:600px](./image/cnn_pre_1.png)
    * 90%의 검증 정확도에 도달
    * 과대적합 문제 발생! -> 데이터 증식 필요
---
## 4.2. 사전 훈련된 Convnet 사용하기
#### 4.2.2.3. Case2: 데이터 증식을 사용한 특성 추출
> **모델 확장** -> 입력 데이터를 사용해 **end-to-end** 로 실행
* 합성곱 기반 층 위에 완전 연결 분류기 추가
* 매우 느림..
* **데이터 증식 사용 가능**
##### 4.2.2.3.1. 합성곱 기반 층 동결
* 훈련하는 동안 가중치가 업데이트되지 않도록 막기
    * 합성곱 기반층에 의해 사전에 학습된 표현이 훈련하는 동안 수정되지 않도록
    * ```conv_base.trainable = False```
---
## 4.2. 사전 훈련된 Convnet 사용하기
##### 4.2.2.3.2. 모델 end-to-end로 훈련
* 훈련 **데이터 증식**하여 훈련 (단 검증, 테스트 데이터는 증식 X)

![width:600px](./image/cnn_pre_2.png)

---
## 4.2. 사전 훈련된 Convnet 사용하기
### 4.2.3. 미세 조정
> 특성 추출에 사용했던 **동결 모델의 상위 층 몇 개를 동결에서 해제**하고 모델에 새로 추가한 층과 함께 훈련
* 맨 위의 **분류기(완전 연결 분류기)가 훈련된 후** 합성곱 기반의 상위 층 미세조정 가능
    * 미리 훈련되지 않으면 훈련하는 동안 너무 큰 오차 신호가 네트워크에 전파
    * 미세조정될 층들이 사전에 학습한 표현 망가뜨리지 않도록 분류기 미리 훈련시키기
#### 4.2.3.1. 미세 조정 단계
1. 사전 훈련된 기반 네트워크 위에 새로운 네트워크 추가
2. 기반 네트워크 동결
3. 새로 추가한 네트워크 훈련
4. 기반 네트워크에서 **일부 층의 동결 해제**
5. 동결 해제한 층과 새로 추가한 층 함께 훈련
---
## 4.2. 사전 훈련된 Convnet 사용하기
#### 4.2.3.2. 왜 미세조정은 적은 층만 하는지?
* 새로운 문제에 재활용하려면 **구체적이고 특화된 특성만 미세 조정**하는 것이 유리!!
    * 하위 층: 일반적이고 재사용 가능한 특성 인코딩
    * **상위 층**: 데이터에 특화된 특성을 인코딩

* 훈련해야 할 파라미터가 많을수록 과대적합의 위험이 커짐
    * **작은 데이터셋으로 합성곱 기반층 전체를 훈련하기엔 위험**
#### 4.2.3.3. 학습률을 낮춘 RMSProp 옵티마이저 사용해 컴파일
* 미세 조정하는 세 개의 층에서 학습된 표현을 조금씩 수정하기 위해 **학습률 낮춤**
    * 변경량이 너무 크면 학습된 표현에 나쁜 영향을 끼칠 수 있음
---
## 4.2. 사전 훈련된 Convnet 사용하기
#### 4.2.3.4. 학습 & 검증 결과 (지수 이동 평균 그래프)
![width:700px](./image/cnn_pre_3.png)
#### 4.2.4. 정리
1. **작은 데이터셋은 과대적합**이 큰 문제 -> **데이터 증식**으로 억제
2. **특성 추출**로 새로운 데이터셋에 **기존 convnet 재사용** 가능
3. 특성 추출을 보완하기 위해 **미세조정** 사용
(미세조정: 기존 모델에서 전에 학습한 표현의 일부를 새로운 문제에 적응시키는 방법)
---
## 4.3. Convnet의 학습 시각화하기
> convnet의 표현은 시각적인 개념을 학습한 것이기 때문에 시각화할 수 있다
### 4.3.1. Convnet 시각화 기법 개요
1. Convnet **중간 층의 출력** 시각화
    * 연속된 컨브넷 층이 입력을 어떻게 변형시킬까?
    * 개별적인 컨브넷 필터의 의미 파악하기

2. Convnet **필터** 시각화
    * 컨브넷 필터가 찾으려는 시각적인 패턴와 개념을 이해하기

3. 클래스 활성화에 대한 **heatmap**을 이미지에 시각화
    * 이미지의 어떤 부분이 주어진 클래스에 속하는 데 기여했을까?
    * 이미지에서 객체 위치를 추정(localization)하기
---
## 4.3. Convnet의 학습 시각화하기
### 4.3.2. 중간 층의 활성화 시각화하기
* 어떤 입력이 주어졌을 때 네트워크에 있는 여러 합성곱과 풀링 층이 출력하는 특성 맵 그리기
* 네트워크에 의해 학습된 필터들이 **어떻게 입력을 분해하는지 보여줌**
#### 4.3.2.1. 결과
![width:1100px](./image/activation_visualization.png)

---
## 4.3. Convnet의 학습 시각화하기
#### 4.3.2.2. 특이점
> 반복적인 변환을 통해 관계없는 정보를 걸러내고 유용한 정보는 강조되고 개선됨
* 1번 층은 초기 사진에 있는 거의 모든 정보가 유지됨
* 상위 층으로 갈수록 활성화는 점점 **추상적**(시각적으로 이해하기 어려워짐)
        * '고양이 귀' , '고양이 눈'처럼 **고수준 개념을 인코딩**하기 시작
    * 이미지의 시각적 콘텐츠 정보 감소
    * **이미지 클래스**(타깃에 관한 정보)**에 관한 정보 증가** 

* **비어있는 활성화**가 층이 깊어지면서 증가
    * 필터에 인코딩된 패턴이 입력 이미지에 나타나지 않았음을 의미
---
## 4.3. Convnet의 학습 시각화하기
### 4.3.3. 컨브넷 필터 시각화하기
* 각 **필터**가 반응하는 **시각적 패턴** 확인하기
* 층과 필터의 **활성화를 최대화하기 위한 손실 함수 정의**
* 빈 입력 이미지에서 시작해 특정 필터의 응답을 최대화 하기 위해 컨브넷 입력 이미지에 **경사 상승법** 사용
    ```python
    # 노이즈가 섞인 회색 이미지로 시작
    input_img_data = np.random.random((1, 150, 150, 3)) * 20 + 128.

    step = 1. # 업데이트할 그래디언트의 크기

    # 경사 상승법 n회 실행
    for i in range(n):   
        # 손실 & 그래디언트를 계산
        loss_value, grads_value = iterate([input_img_data])
        # 손실을 최대화하는 방향으로 입력 이미지 수정
        input_img_data += grads_value * step
    ```
    * 결과적으로 선택된 필터가 최대로 응답하는 이미지가 된다.
---
## 4.3. Convnet의 학습 시각화하기
#### 4.3.3.1. 결과
![width:1150px](./image/filter_visualization.png)
#### 4.3.3.2. 특이점
* 컨브넷의 각 층은 필터의 조합으로 입력을 표현할 수 있는 일련의 필터를 학습!
* 모델의 상위 층으로 갈수록 점점 더 복잡해지고 개선됨.


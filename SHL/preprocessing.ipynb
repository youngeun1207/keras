{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngeun1207/keras/blob/main/SHL/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub3cpV0oareT",
        "outputId": "431259e7-dde0-4fac-c2b7-31087da4b39f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadData(usr, day):\n",
        "  dir_usr = [\"user1\", \"user2\", \"user3\"]\n",
        "  dir_day = [\"day1\", \"day2\", \"day3\"]\n",
        "  file_name = [\"Hand_Motion.txt\",\"Hand_GPS.txt\",\"Hand_Location.txt\", \"Label.txt\"]\n",
        "  path = \"/content/drive/MyDrive/SHLdatasets\"\n",
        "\n",
        "  motion_path = path + \"/\" + dir_usr[usr] + \"/\" + dir_day[day] + \"/\" + file_name[0]\n",
        "  gps_path = path + \"/\" + dir_usr[usr] + \"/\" + dir_day[day] + \"/\" + file_name[1]\n",
        "  location_path = path + \"/\" + dir_usr[usr] + \"/\" + dir_day[day] + \"/\" + file_name[2]\n",
        "  label_path = path + \"/\" + dir_usr[usr] + \"/\" + dir_day[day] + \"/\" + file_name[3]\n",
        "\n",
        "  print(motion_path)\n",
        "\n",
        "  # 'Time', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z'\n",
        "  full_motion = pd.read_csv(motion_path, sep=\" \",header=None, usecols=list(range(10)))\n",
        "  # 'Time', '\bGPS_SNR' , 'GPS_Az, ', 'GPS_Elev', \n",
        "  full_gps = pd.read_csv(gps_path, sep=\" \",header=None, usecols=[0,4,5,6])\n",
        "  # 'Time, Accuracy, Latitude, Longitude, Altitude'\n",
        "  full_location = pd.read_csv(location_path, sep=\" \",header=None, usecols=[0,3,4,5,6])\n",
        "  # Null=0, Still=1, Walking=2, Run=3, Bike=4, Car=5, Bus=6, Train=7, Subway=8\n",
        "  full_label = pd.read_csv(label_path, sep=\" \",header=None, usecols=[1])\n",
        "\n",
        "  full_motion.columns = ['Time', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z']\n",
        "  full_gps.columns = ['Time', '\bGPS_SNR' , 'GPS_Az, ', 'GPS_Elev']\n",
        "  full_location.columns = ['Time', 'Accuracy', 'Latitude', 'Longitude', 'Altitude']\n",
        "  full_label.columns = ['Label']\n",
        "\n",
        "  return full_motion, full_gps, full_location, full_label"
      ],
      "metadata": {
        "id": "gfRlfzuXZwHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeUGT6iUaiCs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "def mergeData(full_motion, full_gps, full_location):\n",
        "  full_motion.iloc[:, 0] = full_motion.iloc[:, 0].astype(int)\n",
        "  full_gps.iloc[:, 0] = full_gps.iloc[:, 0] // 10 * 10\n",
        "  full_location.iloc[:, 0] = full_location.iloc[:, 0] // 10 * 10\n",
        "\n",
        "  full_data = pd.merge(full_motion, full_gps, on='Time', how='left')\n",
        "  full_data = pd.merge(full_data, full_location, on='Time', how='left')\n",
        "  \n",
        "  full_data.fillna(method='ffill', limit=5, axis=0, inplace=True)\n",
        "  full_data.fillna(method='bfill', limit=5, axis=0, inplace=True)\n",
        "  full_data.drop_duplicates('Time', keep='first', inplace=True)\n",
        "\n",
        "  return full_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def toNumpy(data, label):\n",
        "  final_data = data.to_numpy()\n",
        "  final_data = final_data.reshape(-1,1,17)\n",
        "\n",
        "  label_np = label['Label'].T\n",
        "  label_np = label_np.to_numpy()\n",
        "\n",
        "  # one-hot encoding\n",
        "  final_label = np.zeros(shape=(len(label_np), 9))\n",
        "  \n",
        "  label_one_hot = to_categorical(label_np)\n",
        "  # label_one_hot = label_one_hot[0]\n",
        "  for i in range(len(label_one_hot)):\n",
        "    final_label[i] = np.pad(label_one_hot[i], (0,9 - len(label_one_hot[i])), constant_values = 0)\n",
        "\n",
        "  return final_data, final_label"
      ],
      "metadata": {
        "id": "lp3aNUudcAVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getData(usr, day):\n",
        "  usr-=1\n",
        "  day-=1\n",
        "  full_motion, full_gps, full_location, label = loadData(usr, day)\n",
        "  data = mergeData(full_motion, full_gps, full_location)\n",
        "  np_data, np_label = toNumpy(data, label)\n",
        "  return np_data, np_label"
      ],
      "metadata": {
        "id": "yN-iq1ckihER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user 1,2 데이터로 훈련\n",
        "for i in range(2):\n",
        "  for j in range(3):\n",
        "    if(i == 0 and j == 0):\n",
        "      train_data, train_label = getData(1, 1)\n",
        "      continue\n",
        "    tmp_data, tmp_label = getData(i+1, j+1)\n",
        "    train_data = np.concatenate([train_data, tmp_data])\n",
        "    train_label = np.concatenate([train_label, tmp_label])\n",
        "# user 3 데이터로 검증\n",
        "for i in range(3):\n",
        "  if i == 0:\n",
        "    val_data, val_label = getData(3, i+1)\n",
        "    continue\n",
        "  tmp_data, tmp_label = getData(3, i+1)\n",
        "  val_data = np.concatenate([val_data, tmp_data])\n",
        "  val_label = np.concatenate([val_label, tmp_label])\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_label.shape)\n",
        "print(val_data.shape)\n",
        "print(val_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfzT-sm07ceJ",
        "outputId": "0df1ef01-7fdf-4f2a-cdce-d59a11fbe8e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SHLdatasets/user1/day1/Hand_Motion.txt\n",
            "/content/drive/MyDrive/SHLdatasets/user1/day2/Hand_Motion.txt\n",
            "/content/drive/MyDrive/SHLdatasets/user1/day3/Hand_Motion.txt\n",
            "/content/drive/MyDrive/SHLdatasets/user2/day1/Hand_Motion.txt\n",
            "/content/drive/MyDrive/SHLdatasets/user2/day2/Hand_Motion.txt\n",
            "/content/drive/MyDrive/SHLdatasets/user2/day3/Hand_Motion.txt\n",
            "/content/drive/MyDrive/SHLdatasets/user3/day1/Hand_Motion.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_data = np.load(\"/content/drive/MyDrive/SHLdatasets/train_data.npy\")\n",
        "val_data = np.load(\"/content/drive/MyDrive/SHLdatasets/val_data.npy\")\n",
        "train_label = np.load(\"/content/drive/MyDrive/SHLdatasets/train_label.npy\")\n",
        "val_label = np.load(\"/content/drive/MyDrive/SHLdatasets/val_label.npy\")"
      ],
      "metadata": {
        "id": "sC6Ta-VweX3T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.nanmean(train_data, axis=0)\n",
        "train_data = train_data - mean\n",
        "val_data = val_data - mean\n",
        "std = np.nanstd(train_data, axis=0)\n",
        "train_data/=std\n",
        "val_data/=std"
      ],
      "metadata": {
        "id": "KReg0_FbPHCp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[1750000]"
      ],
      "metadata": {
        "id": "zhJf-cqptLKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39666cde-db71-48a2-a33f-7aa5d67db66b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.62667921, -1.7224187 ,  1.06512092,  0.03283842,  0.11032303,\n",
              "         0.13222627,  0.01659528,  1.23409338, -0.63570765, -0.33971381,\n",
              "                nan,         nan,         nan,         nan,         nan,\n",
              "                nan,         nan]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_5sec_10ms(data_10ms, label_10ms):\n",
        "  data_5sec = np.zeros((0, 500, 17))\n",
        "  label_5sec = np.zeros((0, 9))\n",
        "  tmp_data_5sec = np.zeros((0, 17))\n",
        "  tmp_label_5sec = np.zeros((0, 9))\n",
        "  cnt = 0\n",
        "  for i in range(len(data_10ms)):\n",
        "    if(i%10000==0):\n",
        "        print(i)\n",
        "    if cnt == 0:\n",
        "      label = label_10ms[i]\n",
        "      reshape_label = label.reshape((1, 9))\n",
        "      reshape_data_10ms = data_10ms[i][0].reshape((1, 17))\n",
        "      tmp_data_5sec = np.concatenate([tmp_data_5sec, reshape_data_10ms])\n",
        "      cnt+=1\n",
        "      continue\n",
        "    if not all(label_10ms[i] == label): # 5초 이상 동일 이동수단 유지하지 않으면 버리기.\n",
        "      tmp_data_5sec = np.zeros((0, 17)) # 0으로 초기화\n",
        "      tmp_label_5sec = np.zeros((0, 9))\n",
        "      cnt = 0\n",
        "      continue\n",
        "    reshape_data_10ms = data_10ms[i][0].reshape((1, 17))\n",
        "    tmp_data_5sec = np.concatenate([tmp_data_5sec, reshape_data_10ms])\n",
        "    if cnt == 499:\n",
        "      reshape_data = tmp_data_5sec.reshape((1, 500, 17))\n",
        "      data_5sec = np.concatenate([data_5sec, reshape_data])\n",
        "      tmp_data_5sec = np.zeros((0, 17)) # 0으로 초기화\n",
        "      label_5sec = np.concatenate([label_5sec, reshape_label])\n",
        "      cnt = 0\n",
        "      continue\n",
        "    cnt+=1\n",
        "  return data_5sec, label_5sec\n",
        "\n",
        "train_data, train_label = divide_5sec_10ms(train_data, train_label)\n",
        "val_data, val_label = divide_5sec_10ms(val_data, val_label)"
      ],
      "metadata": {
        "id": "JMGL0FvatOax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d19ad783-fd69-4706-83a2-ba1b072f818c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5610000\n",
            "5620000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(train_label.shape)\n",
        "print(val_data.shape)\n",
        "print(val_label.shape)"
      ],
      "metadata": {
        "id": "0xCaxNkWtTGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/SHLdatasets/train_data_5sec',train_data)\n",
        "np.save('/content/drive/MyDrive/SHLdatasets/train_label_5sec',train_label)\n",
        "\n",
        "np.save('/content/drive/MyDrive/SHLdatasets/val_data_5sec',val_data)\n",
        "np.save('/content/drive/MyDrive/SHLdatasets/val_label_5sec',val_label)"
      ],
      "metadata": {
        "id": "c_hjxx316xRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCSe5s7I6xZ0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "def getData(usr, day):\n",
        "  dir_usr = [\"user1\", \"user2\", \"user3\"]\n",
        "  dir_day = [\"day1\", \"day2\", \"day3\"]\n",
        "  file_name = [\"Hand_Motion.txt\",\"Hand_GPS.txt\",\"Label.txt\"]\n",
        "  path = \"/content/drive/MyDrive/SHLdatasets\"\n",
        "\n",
        "  motion_path = path + \"/\" + dir_usr[usr-1] + \"/\" + dir_day[day-1] + \"/\" + file_name[0]\n",
        "  gps_path = path + \"/\" + dir_usr[usr-1] + \"/\" + dir_day[day-1] + \"/\" + file_name[1]\n",
        "  label_path = path + \"/\" + dir_usr[usr-1] + \"/\" + dir_day[day-1] + \"/\" + file_name[2]\n",
        "\n",
        "  print(motion_path)\n",
        "\n",
        "  # 'Time', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z'\n",
        "  full_motion = pd.read_csv(motion_path, sep=\" \",header=None, usecols=list(range(10)))\n",
        "  # 'Time', '\bGPS_SNR' , 'GPS_Az, ', 'GPS_Elev', \n",
        "  full_gps = pd.read_csv(gps_path, sep=\" \",header=None, usecols=[0,4,5,6])\n",
        "  # Null=0, Still=1, Walking=2, Run=3, Bike=4, Car=5, Bus=6, Train=7, Subway=8\n",
        "  full_label = pd.read_csv(label_path, sep=\" \",header=None, usecols=list(range(2)))\n",
        "\n",
        "  # NaN 제거\n",
        "  full_motion = full_motion.fillna(0)\n",
        "  full_gps = full_gps.fillna(0)\n",
        "\n",
        "  # 1sec 단위로 자르기\n",
        "  time = -1\n",
        "  idx2 = 0\n",
        "  data_1sec = pd.DataFrame()\n",
        "  label_1sec = pd.DataFrame()\n",
        "  tmp1 = pd.DataFrame()\n",
        "  tmp2 = pd.DataFrame()\n",
        "  for idx1 in range(len(full_gps)):\n",
        "    gps_time = full_gps.iloc[idx1, 0]//1000\n",
        "    if gps_time - time >= 1:\n",
        "      gap = gps_time - time\n",
        "      time = gps_time\n",
        "      idx2 += gap*100 if idx1 != 0 else 0\n",
        "      if idx2 >= len(full_motion):\n",
        "        break\n",
        "      while time != full_motion.iloc[idx2, 0]//1000:\n",
        "        idx2 += 1\n",
        "      tmp1 = full_gps.iloc[idx1, 1:].T\n",
        "      tmp2 = full_motion.iloc[idx2, 1:].T\n",
        "      data_1sec = data_1sec.append(pd.concat([tmp1, tmp2],ignore_index=True),ignore_index=True)\n",
        "      label_1sec = label_1sec.append(full_label.iloc[idx2, 1:],ignore_index=True)\n",
        "\n",
        "  # 넘파이로 바꾸기\n",
        "  final_data = data_1sec.to_numpy()\n",
        "  final_data = final_data.reshape(-1,1,12)\n",
        "\n",
        "  label_np = label_1sec.T\n",
        "  label_np = label_np.to_numpy()\n",
        "\n",
        "  # one-hot encoding\n",
        "  final_label = np.zeros(shape=(len(label_np[0]), 9))\n",
        "  \n",
        "  label_one_hot = to_categorical(label_np)\n",
        "  label_one_hot = label_one_hot[0]\n",
        "  for i in range(len(label_one_hot)):\n",
        "    final_label[i] = np.pad(label_one_hot[i], (0,9 - len(label_one_hot[i])), constant_values = 0)\n",
        "\n",
        "  return final_data, final_label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ApxKNwAL9BCX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngeun1207/keras/blob/main/SHL/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub3cpV0oareT",
        "outputId": "431259e7-dde0-4fac-c2b7-31087da4b39f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadData(usr, day):\n",
        "  dir_usr = [\"user1\", \"user2\", \"user3\"]\n",
        "  dir_day = [\"day1\", \"day2\", \"day3\"]\n",
        "  file_name = [\"Hand_Motion.txt\",\"Hand_GPS.txt\",\"Hand_Location.txt\", \"Label.txt\"]\n",
        "  path = \"/content/drive/MyDrive/SHLdatasets\"\n",
        "\n",
        "  motion_path = path + \"/\" + dir_usr[usr] + \"/\" + dir_day[day] + \"/\" + file_name[0]\n",
        "  gps_path = path + \"/\" + dir_usr[usr] + \"/\" + dir_day[day] + \"/\" + file_name[1]\n",
        "  location_path = path + \"/\" + dir_usr[usr] + \"/\" + dir_day[day] + \"/\" + file_name[2]\n",
        "  label_path = path + \"/\" + dir_usr[usr] + \"/\" + dir_day[day] + \"/\" + file_name[3]\n",
        "\n",
        "  print(motion_path)\n",
        "\n",
        "  # 'Time', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z'\n",
        "  full_motion = pd.read_csv(motion_path, sep=\" \",header=None, usecols=list(range(10)))\n",
        "  # 'Time', '\bGPS_SNR' , 'GPS_Az, ', 'GPS_Elev', \n",
        "  full_gps = pd.read_csv(gps_path, sep=\" \",header=None, usecols=[0,4,5,6])\n",
        "  # 'Time, Accuracy, Latitude, Longitude, Altitude'\n",
        "  full_location = pd.read_csv(location_path, sep=\" \",header=None, usecols=[0,3,4,5,6])\n",
        "  # Null=0, Still=1, Walking=2, Run=3, Bike=4, Car=5, Bus=6, Train=7, Subway=8\n",
        "  full_label = pd.read_csv(label_path, sep=\" \",header=None, usecols=[1])\n",
        "\n",
        "  full_motion.columns = ['Time', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z']\n",
        "  full_gps.columns = ['Time', '\bGPS_SNR' , 'GPS_Az, ', 'GPS_Elev']\n",
        "  full_location.columns = ['Time', 'Accuracy', 'Latitude', 'Longitude', 'Altitude']\n",
        "  full_label.columns = ['Label']\n",
        "\n",
        "  return full_motion, full_gps, full_location, full_label"
      ],
      "metadata": {
        "id": "gfRlfzuXZwHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeUGT6iUaiCs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "def mergeData(full_motion, full_gps, full_location):\n",
        "  full_motion.iloc[:, 0] = full_motion.iloc[:, 0].astype(int)\n",
        "  full_gps.iloc[:, 0] = full_gps.iloc[:, 0] // 10 * 10\n",
        "  full_location.iloc[:, 0] = full_location.iloc[:, 0] // 10 * 10\n",
        "\n",
        "  full_data = pd.merge(full_motion, full_gps, on='Time', how='left')\n",
        "  full_data = pd.merge(full_data, full_location, on='Time', how='left')\n",
        "  \n",
        "  full_data.fillna(method='ffill', limit=5, axis=0, inplace=True)\n",
        "  full_data.fillna(method='bfill', limit=5, axis=0, inplace=True)\n",
        "  full_data.drop_duplicates('Time', keep='first', inplace=True)\n",
        "\n",
        "  return full_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def toNumpy(data, label):\n",
        "  final_data = data.to_numpy()\n",
        "  final_data = final_data.reshape(-1,1,17)\n",
        "\n",
        "  label_np = label['Label'].T\n",
        "  label_np = label_np.to_numpy()\n",
        "\n",
        "  # one-hot encoding\n",
        "  final_label = np.zeros(shape=(len(label_np), 9))\n",
        "  \n",
        "  label_one_hot = to_categorical(label_np)\n",
        "  # label_one_hot = label_one_hot[0]\n",
        "  for i in range(len(label_one_hot)):\n",
        "    final_label[i] = np.pad(label_one_hot[i], (0,9 - len(label_one_hot[i])), constant_values = 0)\n",
        "\n",
        "  return final_data, final_label"
      ],
      "metadata": {
        "id": "lp3aNUudcAVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getData(usr, day):\n",
        "  usr-=1\n",
        "  day-=1\n",
        "  full_motion, full_gps, full_location, label = loadData(usr, day)\n",
        "  data = mergeData(full_motion, full_gps, full_location)\n",
        "  np_data, np_label = toNumpy(data, label)\n",
        "  return np_data, np_label"
      ],
      "metadata": {
        "id": "yN-iq1ckihER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user 1,2 데이터로 훈련\n",
        "for i in range(2):\n",
        "  for j in range(3):\n",
        "    if(i == 0 and j == 0):\n",
        "      train_data, train_label = getData(1, 1)\n",
        "      continue\n",
        "    tmp_data, tmp_label = getData(i+1, j+1)\n",
        "    train_data = np.concatenate([train_data, tmp_data])\n",
        "    train_label = np.concatenate([train_label, tmp_label])\n",
        "# user 3 데이터로 검증\n",
        "for i in range(3):\n",
        "  if i == 0:\n",
        "    val_data, val_label = getData(3, i+1)\n",
        "    continue\n",
        "  tmp_data, tmp_label = getData(3, i+1)\n",
        "  val_data = np.concatenate([val_data, tmp_data])\n",
        "  val_label = np.concatenate([val_label, tmp_label])\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_label.shape)\n",
        "print(val_data.shape)\n",
        "print(val_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfzT-sm07ceJ",
        "outputId": "0df1ef01-7fdf-4f2a-cdce-d59a11fbe8e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SHLdatasets/user1/day1/Hand_Motion.txt\n",
            "/content/drive/MyDrive/SHLdatasets/user1/day2/Hand_Motion.txt\n",
            "/content/drive/MyDrive/SHLdatasets/user1/day3/Hand_Motion.txt\n",
            "/content/drive/MyDrive/SHLdatasets/user2/day1/Hand_Motion.txt\n",
            "/content/drive/MyDrive/SHLdatasets/user2/day2/Hand_Motion.txt\n",
            "/content/drive/MyDrive/SHLdatasets/user2/day3/Hand_Motion.txt\n",
            "/content/drive/MyDrive/SHLdatasets/user3/day1/Hand_Motion.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_data = np.load(\"/content/drive/MyDrive/SHLdatasets/train_data.npy\")\n",
        "val_data = np.load(\"/content/drive/MyDrive/SHLdatasets/val_data.npy\")\n",
        "train_label = np.load(\"/content/drive/MyDrive/SHLdatasets/train_label.npy\")\n",
        "val_label = np.load(\"/content/drive/MyDrive/SHLdatasets/val_label.npy\")"
      ],
      "metadata": {
        "id": "sC6Ta-VweX3T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.nanmean(train_data, axis=0)\n",
        "train_data = train_data - mean\n",
        "val_data = val_data - mean\n",
        "std = np.nanstd(train_data, axis=0)\n",
        "train_data/=std\n",
        "val_data/=std"
      ],
      "metadata": {
        "id": "KReg0_FbPHCp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[1750000]"
      ],
      "metadata": {
        "id": "zhJf-cqptLKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39666cde-db71-48a2-a33f-7aa5d67db66b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.62667921, -1.7224187 ,  1.06512092,  0.03283842,  0.11032303,\n",
              "         0.13222627,  0.01659528,  1.23409338, -0.63570765, -0.33971381,\n",
              "                nan,         nan,         nan,         nan,         nan,\n",
              "                nan,         nan]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_5sec_10ms(data_10ms, label_10ms):\n",
        "  data_5sec = np.zeros((0, 500, 17))\n",
        "  label_5sec = np.zeros((0, 9))\n",
        "  tmp_data_5sec = np.zeros((0, 17))\n",
        "  tmp_label_5sec = np.zeros((0, 9))\n",
        "  cnt = 0\n",
        "  for i in range(len(data_10ms)):\n",
        "    if(i%10000==0):\n",
        "        print(i)\n",
        "    if cnt == 0:\n",
        "      label = label_10ms[i]\n",
        "      reshape_label = label.reshape((1, 9))\n",
        "      reshape_data_10ms = data_10ms[i][0].reshape((1, 17))\n",
        "      tmp_data_5sec = np.concatenate([tmp_data_5sec, reshape_data_10ms])\n",
        "      cnt+=1\n",
        "      continue\n",
        "    if not all(label_10ms[i] == label): # 5초 이상 동일 이동수단 유지하지 않으면 버리기.\n",
        "      tmp_data_5sec = np.zeros((0, 17)) # 0으로 초기화\n",
        "      tmp_label_5sec = np.zeros((0, 9))\n",
        "      cnt = 0\n",
        "      continue\n",
        "    reshape_data_10ms = data_10ms[i][0].reshape((1, 17))\n",
        "    tmp_data_5sec = np.concatenate([tmp_data_5sec, reshape_data_10ms])\n",
        "    if cnt == 499:\n",
        "      reshape_data = tmp_data_5sec.reshape((1, 500, 17))\n",
        "      data_5sec = np.concatenate([data_5sec, reshape_data])\n",
        "      tmp_data_5sec = np.zeros((0, 17)) # 0으로 초기화\n",
        "      label_5sec = np.concatenate([label_5sec, reshape_label])\n",
        "      cnt = 0\n",
        "      continue\n",
        "    cnt+=1\n",
        "  return data_5sec, label_5sec\n",
        "\n",
        "train_data, train_label = divide_5sec_10ms(train_data, train_label)\n",
        "val_data, val_label = divide_5sec_10ms(val_data, val_label)"
      ],
      "metadata": {
        "id": "JMGL0FvatOax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fccadf9f-e12c-426a-c090-dc8ffa6e39e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n",
            "140000\n",
            "150000\n",
            "160000\n",
            "170000\n",
            "180000\n",
            "190000\n",
            "200000\n",
            "210000\n",
            "220000\n",
            "230000\n",
            "240000\n",
            "250000\n",
            "260000\n",
            "270000\n",
            "280000\n",
            "290000\n",
            "300000\n",
            "310000\n",
            "320000\n",
            "330000\n",
            "340000\n",
            "350000\n",
            "360000\n",
            "370000\n",
            "380000\n",
            "390000\n",
            "400000\n",
            "410000\n",
            "420000\n",
            "430000\n",
            "440000\n",
            "450000\n",
            "460000\n",
            "470000\n",
            "480000\n",
            "490000\n",
            "500000\n",
            "510000\n",
            "520000\n",
            "530000\n",
            "540000\n",
            "550000\n",
            "560000\n",
            "570000\n",
            "580000\n",
            "590000\n",
            "600000\n",
            "610000\n",
            "620000\n",
            "630000\n",
            "640000\n",
            "650000\n",
            "660000\n",
            "670000\n",
            "680000\n",
            "690000\n",
            "700000\n",
            "710000\n",
            "720000\n",
            "730000\n",
            "740000\n",
            "750000\n",
            "760000\n",
            "770000\n",
            "780000\n",
            "790000\n",
            "800000\n",
            "810000\n",
            "820000\n",
            "830000\n",
            "840000\n",
            "850000\n",
            "860000\n",
            "870000\n",
            "880000\n",
            "890000\n",
            "900000\n",
            "910000\n",
            "920000\n",
            "930000\n",
            "940000\n",
            "950000\n",
            "960000\n",
            "970000\n",
            "980000\n",
            "990000\n",
            "1000000\n",
            "1010000\n",
            "1020000\n",
            "1030000\n",
            "1040000\n",
            "1050000\n",
            "1060000\n",
            "1070000\n",
            "1080000\n",
            "1090000\n",
            "1100000\n",
            "1110000\n",
            "1120000\n",
            "1130000\n",
            "1140000\n",
            "1150000\n",
            "1160000\n",
            "1170000\n",
            "1180000\n",
            "1190000\n",
            "1200000\n",
            "1210000\n",
            "1220000\n",
            "1230000\n",
            "1240000\n",
            "1250000\n",
            "1260000\n",
            "1270000\n",
            "1280000\n",
            "1290000\n",
            "1300000\n",
            "1310000\n",
            "1320000\n",
            "1330000\n",
            "1340000\n",
            "1350000\n",
            "1360000\n",
            "1370000\n",
            "1380000\n",
            "1390000\n",
            "1400000\n",
            "1410000\n",
            "1420000\n",
            "1430000\n",
            "1440000\n",
            "1450000\n",
            "1460000\n",
            "1470000\n",
            "1480000\n",
            "1490000\n",
            "1500000\n",
            "1510000\n",
            "1520000\n",
            "1530000\n",
            "1540000\n",
            "1550000\n",
            "1560000\n",
            "1570000\n",
            "1580000\n",
            "1590000\n",
            "1600000\n",
            "1610000\n",
            "1620000\n",
            "1630000\n",
            "1640000\n",
            "1650000\n",
            "1660000\n",
            "1670000\n",
            "1680000\n",
            "1690000\n",
            "1700000\n",
            "1710000\n",
            "1720000\n",
            "1730000\n",
            "1740000\n",
            "1750000\n",
            "1760000\n",
            "1770000\n",
            "1780000\n",
            "1790000\n",
            "1800000\n",
            "1810000\n",
            "1820000\n",
            "1830000\n",
            "1840000\n",
            "1850000\n",
            "1860000\n",
            "1870000\n",
            "1880000\n",
            "1890000\n",
            "1900000\n",
            "1910000\n",
            "1920000\n",
            "1930000\n",
            "1940000\n",
            "1950000\n",
            "1960000\n",
            "1970000\n",
            "1980000\n",
            "1990000\n",
            "2000000\n",
            "2010000\n",
            "2020000\n",
            "2030000\n",
            "2040000\n",
            "2050000\n",
            "2060000\n",
            "2070000\n",
            "2080000\n",
            "2090000\n",
            "2100000\n",
            "2110000\n",
            "2120000\n",
            "2130000\n",
            "2140000\n",
            "2150000\n",
            "2160000\n",
            "2170000\n",
            "2180000\n",
            "2190000\n",
            "2200000\n",
            "2210000\n",
            "2220000\n",
            "2230000\n",
            "2240000\n",
            "2250000\n",
            "2260000\n",
            "2270000\n",
            "2280000\n",
            "2290000\n",
            "2300000\n",
            "2310000\n",
            "2320000\n",
            "2330000\n",
            "2340000\n",
            "2350000\n",
            "2360000\n",
            "2370000\n",
            "2380000\n",
            "2390000\n",
            "2400000\n",
            "2410000\n",
            "2420000\n",
            "2430000\n",
            "2440000\n",
            "2450000\n",
            "2460000\n",
            "2470000\n",
            "2480000\n",
            "2490000\n",
            "2500000\n",
            "2510000\n",
            "2520000\n",
            "2530000\n",
            "2540000\n",
            "2550000\n",
            "2560000\n",
            "2570000\n",
            "2580000\n",
            "2590000\n",
            "2600000\n",
            "2610000\n",
            "2620000\n",
            "2630000\n",
            "2640000\n",
            "2650000\n",
            "2660000\n",
            "2670000\n",
            "2680000\n",
            "2690000\n",
            "2700000\n",
            "2710000\n",
            "2720000\n",
            "2730000\n",
            "2740000\n",
            "2750000\n",
            "2760000\n",
            "2770000\n",
            "2780000\n",
            "2790000\n",
            "2800000\n",
            "2810000\n",
            "2820000\n",
            "2830000\n",
            "2840000\n",
            "2850000\n",
            "2860000\n",
            "2870000\n",
            "2880000\n",
            "2890000\n",
            "2900000\n",
            "2910000\n",
            "2920000\n",
            "2930000\n",
            "2940000\n",
            "2950000\n",
            "2960000\n",
            "2970000\n",
            "2980000\n",
            "2990000\n",
            "3000000\n",
            "3010000\n",
            "3020000\n",
            "3030000\n",
            "3040000\n",
            "3050000\n",
            "3060000\n",
            "3070000\n",
            "3080000\n",
            "3090000\n",
            "3100000\n",
            "3110000\n",
            "3120000\n",
            "3130000\n",
            "3140000\n",
            "3150000\n",
            "3160000\n",
            "3170000\n",
            "3180000\n",
            "3190000\n",
            "3200000\n",
            "3210000\n",
            "3220000\n",
            "3230000\n",
            "3240000\n",
            "3250000\n",
            "3260000\n",
            "3270000\n",
            "3280000\n",
            "3290000\n",
            "3300000\n",
            "3310000\n",
            "3320000\n",
            "3330000\n",
            "3340000\n",
            "3350000\n",
            "3360000\n",
            "3370000\n",
            "3380000\n",
            "3390000\n",
            "3400000\n",
            "3410000\n",
            "3420000\n",
            "3430000\n",
            "3440000\n",
            "3450000\n",
            "3460000\n",
            "3470000\n",
            "3480000\n",
            "3490000\n",
            "3500000\n",
            "3510000\n",
            "3520000\n",
            "3530000\n",
            "3540000\n",
            "3550000\n",
            "3560000\n",
            "3570000\n",
            "3580000\n",
            "3590000\n",
            "3600000\n",
            "3610000\n",
            "3620000\n",
            "3630000\n",
            "3640000\n",
            "3650000\n",
            "3660000\n",
            "3670000\n",
            "3680000\n",
            "3690000\n",
            "3700000\n",
            "3710000\n",
            "3720000\n",
            "3730000\n",
            "3740000\n",
            "3750000\n",
            "3760000\n",
            "3770000\n",
            "3780000\n",
            "3790000\n",
            "3800000\n",
            "3810000\n",
            "3820000\n",
            "3830000\n",
            "3840000\n",
            "3850000\n",
            "3860000\n",
            "3870000\n",
            "3880000\n",
            "3890000\n",
            "3900000\n",
            "3910000\n",
            "3920000\n",
            "3930000\n",
            "3940000\n",
            "3950000\n",
            "3960000\n",
            "3970000\n",
            "3980000\n",
            "3990000\n",
            "4000000\n",
            "4010000\n",
            "4020000\n",
            "4030000\n",
            "4040000\n",
            "4050000\n",
            "4060000\n",
            "4070000\n",
            "4080000\n",
            "4090000\n",
            "4100000\n",
            "4110000\n",
            "4120000\n",
            "4130000\n",
            "4140000\n",
            "4150000\n",
            "4160000\n",
            "4170000\n",
            "4180000\n",
            "4190000\n",
            "4200000\n",
            "4210000\n",
            "4220000\n",
            "4230000\n",
            "4240000\n",
            "4250000\n",
            "4260000\n",
            "4270000\n",
            "4280000\n",
            "4290000\n",
            "4300000\n",
            "4310000\n",
            "4320000\n",
            "4330000\n",
            "4340000\n",
            "4350000\n",
            "4360000\n",
            "4370000\n",
            "4380000\n",
            "4390000\n",
            "4400000\n",
            "4410000\n",
            "4420000\n",
            "4430000\n",
            "4440000\n",
            "4450000\n",
            "4460000\n",
            "4470000\n",
            "4480000\n",
            "4490000\n",
            "4500000\n",
            "4510000\n",
            "4520000\n",
            "4530000\n",
            "4540000\n",
            "4550000\n",
            "4560000\n",
            "4570000\n",
            "4580000\n",
            "4590000\n",
            "4600000\n",
            "4610000\n",
            "4620000\n",
            "4630000\n",
            "4640000\n",
            "4650000\n",
            "4660000\n",
            "4670000\n",
            "4680000\n",
            "4690000\n",
            "4700000\n",
            "4710000\n",
            "4720000\n",
            "4730000\n",
            "4740000\n",
            "4750000\n",
            "4760000\n",
            "4770000\n",
            "4780000\n",
            "4790000\n",
            "4800000\n",
            "4810000\n",
            "4820000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(train_label.shape)\n",
        "print(val_data.shape)\n",
        "print(val_label.shape)"
      ],
      "metadata": {
        "id": "0xCaxNkWtTGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/SHLdatasets/train_data_5sec',train_data)\n",
        "np.save('/content/drive/MyDrive/SHLdatasets/train_label_5sec',train_label)\n",
        "\n",
        "np.save('/content/drive/MyDrive/SHLdatasets/val_data_5sec',val_data)\n",
        "np.save('/content/drive/MyDrive/SHLdatasets/val_label_5sec',val_label)"
      ],
      "metadata": {
        "id": "c_hjxx316xRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.nan_to_num(train_data)\n",
        "val_data = np.nan_to_num(val_data)"
      ],
      "metadata": {
        "id": "BIwoLLNQfsuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import dropout\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.LSTM(32, input_shape=(500, 12), return_sequences=True))\n",
        "model.add(layers.LSTM(16, dropout = 0.1, recurrent_dropout = 0.5))\n",
        "model.add(layers.Dense(9, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "             loss= 'categorical_crossentropy',\n",
        "             metrics= ['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(train_data,\n",
        "                     train_label,\n",
        "                     epochs=50,\n",
        "                     batch_size=256,\n",
        "                     validation_data = (val_data, val_label))"
      ],
      "metadata": {
        "id": "TrwGqKWhgq8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(acc)+1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MWP0C07Fg2n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCSe5s7I6xZ0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "def getData(usr, day):\n",
        "  dir_usr = [\"user1\", \"user2\", \"user3\"]\n",
        "  dir_day = [\"day1\", \"day2\", \"day3\"]\n",
        "  file_name = [\"Hand_Motion.txt\",\"Hand_GPS.txt\",\"Label.txt\"]\n",
        "  path = \"/content/drive/MyDrive/SHLdatasets\"\n",
        "\n",
        "  motion_path = path + \"/\" + dir_usr[usr-1] + \"/\" + dir_day[day-1] + \"/\" + file_name[0]\n",
        "  gps_path = path + \"/\" + dir_usr[usr-1] + \"/\" + dir_day[day-1] + \"/\" + file_name[1]\n",
        "  label_path = path + \"/\" + dir_usr[usr-1] + \"/\" + dir_day[day-1] + \"/\" + file_name[2]\n",
        "\n",
        "  print(motion_path)\n",
        "\n",
        "  # 'Time', 'Acc_X', 'Acc_Y', 'Acc_Z', 'Gyr_X', 'Gyr_Y', 'Gyr_Z', 'Mag_X', 'Mag_Y', 'Mag_Z'\n",
        "  full_motion = pd.read_csv(motion_path, sep=\" \",header=None, usecols=list(range(10)))\n",
        "  # 'Time', '\bGPS_SNR' , 'GPS_Az, ', 'GPS_Elev', \n",
        "  full_gps = pd.read_csv(gps_path, sep=\" \",header=None, usecols=[0,4,5,6])\n",
        "  # Null=0, Still=1, Walking=2, Run=3, Bike=4, Car=5, Bus=6, Train=7, Subway=8\n",
        "  full_label = pd.read_csv(label_path, sep=\" \",header=None, usecols=list(range(2)))\n",
        "\n",
        "  # NaN 제거\n",
        "  full_motion = full_motion.fillna(0)\n",
        "  full_gps = full_gps.fillna(0)\n",
        "\n",
        "  # 1sec 단위로 자르기\n",
        "  time = -1\n",
        "  idx2 = 0\n",
        "  data_1sec = pd.DataFrame()\n",
        "  label_1sec = pd.DataFrame()\n",
        "  tmp1 = pd.DataFrame()\n",
        "  tmp2 = pd.DataFrame()\n",
        "  for idx1 in range(len(full_gps)):\n",
        "    gps_time = full_gps.iloc[idx1, 0]//1000\n",
        "    if gps_time - time >= 1:\n",
        "      gap = gps_time - time\n",
        "      time = gps_time\n",
        "      idx2 += gap*100 if idx1 != 0 else 0\n",
        "      if idx2 >= len(full_motion):\n",
        "        break\n",
        "      while time != full_motion.iloc[idx2, 0]//1000:\n",
        "        idx2 += 1\n",
        "      tmp1 = full_gps.iloc[idx1, 1:].T\n",
        "      tmp2 = full_motion.iloc[idx2, 1:].T\n",
        "      data_1sec = data_1sec.append(pd.concat([tmp1, tmp2],ignore_index=True),ignore_index=True)\n",
        "      label_1sec = label_1sec.append(full_label.iloc[idx2, 1:],ignore_index=True)\n",
        "\n",
        "  # 넘파이로 바꾸기\n",
        "  final_data = data_1sec.to_numpy()\n",
        "  final_data = final_data.reshape(-1,1,12)\n",
        "\n",
        "  label_np = label_1sec.T\n",
        "  label_np = label_np.to_numpy()\n",
        "\n",
        "  # one-hot encoding\n",
        "  final_label = np.zeros(shape=(len(label_np[0]), 9))\n",
        "  \n",
        "  label_one_hot = to_categorical(label_np)\n",
        "  label_one_hot = label_one_hot[0]\n",
        "  for i in range(len(label_one_hot)):\n",
        "    final_label[i] = np.pad(label_one_hot[i], (0,9 - len(label_one_hot[i])), constant_values = 0)\n",
        "\n",
        "  return final_data, final_label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ApxKNwAL9BCX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}